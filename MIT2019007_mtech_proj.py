# -*- coding: utf-8 -*-
"""Mtech Proj

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11LXa4kIt2J8DDRsgGR1hCsx6uVQLpjgY
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sb

# %matplotlib inline

dataset = pd.read_csv("/content/drive/My Drive/heart_dataset.csv")

# dataset.describe()

# print(dataset.corr()["target"].abs().sort_values(ascending = False))

# tar = dataset["target"]
# sb.countplot(tar)
print(dataset.corr()["target"].abs().sort_values(ascending=False))

# sb.barplot(dataset,tar)

# sb.barplot(dataset.exang,tar)

# sb.barplot(dataset.cp,tar)

# sb.barplot(dataset.restecg,tar)

# sb.barplot(dataset.ca,tar)

# sb.barplot(dataset.thal,tar)

# sb.countplot(dataset.thal)

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn import svm
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, StackingClassifier, AdaBoostClassifier

from sklearn.neural_network import MLPClassifier

datas = dataset.drop("target",axis=1)
target = dataset["target"]

X_train,X_test,Y_train,Y_test = train_test_split(datas,target,test_size=0.30,random_state=5)

lr = LogisticRegression(max_iter=1000,)
lr.fit(X_train,Y_train)

Y_pred_lr = lr.predict(X_test)
score_lr = round(accuracy_score(Y_pred_lr,Y_test)*100,2)

print("The accuracy (Logistic Regression): "+str(score_lr)+" %")
X_test.shape
X_train.shape

nb = GaussianNB()
nb.fit(X_train,Y_train)
Y_pred_nb = nb.predict(X_test)
score_nb = round(accuracy_score(Y_pred_nb,Y_test)*100,2)
print("The accuracy (Naive Bayes): "+str(score_nb)+" %")

sv = svm.SVC(kernel='linear', )
sv.fit(X_train, Y_train)
Y_pred_svm = sv.predict(X_test)
score_svm = round(accuracy_score(Y_pred_svm,Y_test)*100,2)
print("The accuracy (Linear SVM): "+str(score_svm)+" %")

knn = KNeighborsClassifier(n_neighbors=7)
knn.fit(X_train,Y_train)
Y_pred_knn=knn.predict(X_test)
score_knn = round(accuracy_score(Y_pred_knn,Y_test)*100,2)
print("The accuracy (KNN): "+str(score_knn)+" %")

max_accuracy = 0


for x in range(400):
    dt = DecisionTreeClassifier(random_state=x, )
    dt.fit(X_train,Y_train)
    Y_pred_dt = dt.predict(X_test)
    current_accuracy = round(accuracy_score(Y_pred_dt,Y_test)*100,2)
    if(current_accuracy>max_accuracy):
        max_accuracy = current_accuracy
        best_x = x
              
# print(max_accuracy)
# print(best_x)


dt = DecisionTreeClassifier(random_state=best_x)
dt.fit(X_train,Y_train)
Y_pred_dt = dt.predict(X_test)
score_dt = round(accuracy_score(Y_pred_dt,Y_test)*100,2)
print("The accuracy (Decision Tree): "+str(score_dt)+" %")

# max_accuracy = 0


# for x in range(200):
#     rf = RandomForestClassifier(random_state=x)
#     rf.fit(X_train,Y_train)
#     Y_pred_rf = rf.predict(X_test)
#     current_accuracy = round(accuracy_score(Y_pred_rf,Y_test)*100,2)
#     if(current_accuracy>max_accuracy):
#         max_accuracy = current_accuracy
#         best_x = x
        
#print(max_accuracy)
#print(best_x)

# rf = RandomForestClassifier(random_state=best_x)
rf = RandomForestClassifier(random_state=83,)
rf.fit(X_train,Y_train)
Y_pred_rf = rf.predict(X_test)
score_rf = round(accuracy_score(Y_pred_rf,Y_test)*100,2)
print("The accuracy (Random Forest): "+str(score_rf)+" %")

print(best_x)

mlp2 = MLPClassifier(hidden_layer_sizes=(7,5), max_iter=2000, random_state=3,activation='relu')
# mlp2 = MLPClassifier(hidden_layer_sizes=(7,5), max_iter=2000, random_state=3,activation='relu')
mlp2.fit(X_train, Y_train)
predictions2 = mlp2.predict(X_test)
score_mlp = round(accuracy_score(predictions2,Y_test)*100,2)

print("The accuracy (Logistic Regression): "+str(score_lr)+" %")
print("The accuracy (Naive Bayes): "+str(score_nb)+" %")
print("The accuracy (Linear SVM): "+str(score_svm)+" %")
print("The accuracy (KNN): "+str(score_knn)+" %")
print("The accuracy (Decision Tree): "+str(score_dt)+" %")
print("The accuracy (Random Forest): "+str(score_rf)+" %")
print("The accuracy (MLP[7,5]): "+str(score_mlp)+" %")

# mlp = MLPClassifier(hidden_layer_sizes=(14), max_iter=2000, random_state=7, activation='logistic')
mlp = MLPClassifier(hidden_layer_sizes=(5), max_iter=1000, random_state=7, activation='logistic')
base_learners = [
                 ('base7', rf), 
                 ('base1', knn),
                 ('base2', dt), 
                 ('base3', nb), 
                 ('base5', sv), 
                 ('base6', lr), 
                 ('base4', mlp2)
                ]

clf = StackingClassifier(estimators=base_learners, final_estimator=mlp)
# clf = StackingClassifier(estimators=base_learners, final_estimator=LogisticRegression())
finalPred = clf.fit(X_train, Y_train).score(X_test, Y_test)
finalAcc = round(finalPred*100,2)
print("The accuracy Ensemble(Stacking): "+str(finalAcc)+" %")
mlpPred = clf.predict(X_test)

print("Confusion Matrix:\n", confusion_matrix(Y_test, mlpPred))
print(classification_report(Y_test,mlpPred))

from sklearn.ensemble import VotingClassifier 
clf2 = VotingClassifier(estimators=base_learners, )

confidence = clf2.fit(X_train, Y_train).score(X_test, Y_test)
VotePred = clf2.predict(X_test)
print('Final Accuracy Ensemble(Voting):', round(confidence *100,2),"%")
print(classification_report(Y_test,VotePred))

abc = AdaBoostClassifier(n_estimators=100, base_estimator=rf, random_state=83, learning_rate=0.2)
modelx = abc.fit(X_train, Y_train)
y_predx = modelx.predict(X_test)
print("Accuracy(Adaboost [LR]):",accuracy_score(Y_test, y_predx))

abc = AdaBoostClassifier(n_estimators=100, base_estimator=sv, random_state=5, algorithm='SAMME',learning_rate=0.2)
modelx = abc.fit(X_train, Y_train)
y_predx = modelx.predict(X_test)
print("Accuracy(Adaboost [SVM]):",accuracy_score(Y_test, y_predx))

abc = AdaBoostClassifier(n_estimators=100, base_estimator=lr, random_state=13, algorithm='SAMME',learning_rate=0.2)
modelx = abc.fit(X_train, Y_train)
y_predx = modelx.predict(X_test)
print("Accuracy(Adaboost [RF]):",accuracy_score(Y_test, y_predx))

abc = AdaBoostClassifier(n_estimators=100, base_estimator=dt, random_state=9, algorithm='SAMME',learning_rate=0.2)
modelx = abc.fit(X_train, Y_train)
y_predx = modelx.predict(X_test)
print("Accuracy(Adaboost [DT]):",accuracy_score(Y_test, y_predx))

abc = AdaBoostClassifier(n_estimators=100, base_estimator=nb, random_state=10, algorithm='SAMME',learning_rate=0.2)
modelx = abc.fit(X_train, Y_train)
y_predx = modelx.predict(X_test)
print("Accuracy(Adaboost [NB]):",accuracy_score(Y_test, y_predx))